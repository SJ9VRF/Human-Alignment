# Install required packages (if not already installed)
!pip install google-cloud-aiplatform google-cloud-pipeline-components pandas kfp

# Import the HumanAlignment class
from human_alignment import HumanAlignment

# Step 1: Set up the project and initialize HumanAlignment
project_id = "your-project-id"
location = "us-central1"
bucket_name = None  # Optional: Leave as None to auto-generate a bucket name

alignment = HumanAlignment(project_id=project_id, location=location, bucket_name=bucket_name)

# Step 2: Create the bucket
alignment.create_bucket()

# Step 3: Prepare the dataset
context = [
    "Context for example 1",
    "Context for example 2",
]
questions = [
    "What is the first question?",
    "What is the second question?",
]
predictions_a = [
    "Prediction from model A for example 1",
    "Prediction from model A for example 2",
]
predictions_b = [
    "Prediction from model B for example 1",
    "Prediction from model B for example 2",
]
human_preference = ["A", "B"]  # Human preferences for each example

alignment.prepare_dataset(context, questions, predictions_a, predictions_b, human_preference)

# Step 4: Compile the pipeline
from google_cloud_pipeline_components.v1 import model_evaluation

alignment.compile_pipeline(pipeline_func=model_evaluation.autosxs_pipeline)

# Step 5: Define pipeline parameters
parameters = {
    "evaluation_dataset": alignment.dataset_path,
    "id_columns": ["questions"],
    "autorater_prompt_parameters": {
        "inference_context": {"column": "context"},
        "inference_instruction": {"column": "questions"},
    },
    "task": "question_answering",
    "response_column_a": "pred_a",
    "response_column_b": "pred_b",
    "human_preference_column": "actuals",
}

# Step 6: Run the pipeline
display_name = "human-alignment-demo"
job = alignment.run_pipeline(parameters, display_name=display_name)

# Step 7: Monitor pipeline progress
print(f"Pipeline {display_name} is running. Check the Vertex AI console for progress.")

# Step 8: Fetch results once the pipeline completes
outputs = alignment.fetch_job_outputs(job, task_name="online-evaluation-pairwise")
judgments_uri = outputs["judgments"].artifacts[0].uri

# Load and display judgments
judgments_df = alignment.load_metrics(judgments_uri)
print("Judgments:")
print(judgments_df)

# Step 9: Clean up resources (Optional)
alignment.clean_up(delete_bucket=True)
